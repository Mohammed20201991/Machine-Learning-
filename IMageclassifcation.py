# -*- coding: utf-8 -*-
"""Copy of SAML Assignment 1

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17rvlItrFWYkk23mW1aXS_Jgc-lYGD2J2

# Assignment 1 - Image Classification

This notebook contains the required task for the first assignment of the Software for Advanced Machine Learning course. Read the task description and implement the empty code cells. Each section represents a stage along implementing an image classifier, from loading and inspecting the dataset to training a **pre-trained** Convolutional Neural Network architecture. The sections are to guide you but you do not have to follow that specific order. 

Copy this notebook to your drive (File -> Save a copy in Drive), edit it and upload the final ipynb file to [Canvas](https://canvas.elte.hu) or upload the link to the Colab notebook itself. If you have your own machine with Jupyter installed, you can work there as well.

**Note** Make sure the notebook is using GPU accelerataion in Edit -> Notebook settings, otherwise training and evaluation can be very slow.

## Rules and Comments
- From the list of datasets and architectures listed in canvas, each student was atributed **1 dataset and 1 architecture** to use within this assignment. Please confirm yours in the Canvas assignment's description. 
- This is an DL class so to pass the homework you do have to implement a working classifier, just loading the data or having a "random-guess" performance is not enough.
- As always, copying others' code will make you fail the homework automatically (and thus the course). Remember that you will have to defend the assignment at the end of the semester.
- **Deadline is October 21**
- Make sure your code can be run from an empty state (use Runtime -> Run all in the menu after restarting the notebook)
- Feel free to add more code cells as needed. But don't put code into external Python files to ease the reviewing.
- Please add your name and Neptun ID below for easier identification.

**Name:**  
**Neptun ID:** 
#pretrained Convolutional Neural Network architecture on a dataset, both given in canvas. The datasets contain images as input and class labels as target, thus you have to solve a Supervised Machine Learning Classification problem. 

The dataset shoud be divided into train, validation and test set, for which results should be presented for all.

You can either train the architecture you were given without changing its layers, or you can add more layers, if you believe it increases the accuracy. There is no expected percentage of accuracy, but **your accuracy should be better than random guessing and your loss has to decrease throughout the epochs**. We expect you to use Tensorboard for visualizing the accuracy, loss and details about the model and use Early stopping while training your network.

# ADD YOUR CODE HERE

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np #for basic array operations
import tarfile
import torch
import torchvision    #has various utils functions, including loading datasets
import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions #creating neural network 
import torch.nn.functional as F   #functional api for layers,...
import torchvision.models as models
from torchvision import datasets
import torch.optim as optim 
from torch.utils.data.sampler import SubsetRandomSampler
import torchvision.transforms as transforms   #common image transformations
from torchvision.datasets.utils import download_url
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
from torch.utils.data import random_split
from torchvision.utils import make_grid
from torchvision.transforms import ToTensor
import matplotlib.pyplot as plt   #for data or image  visualization
# %matplotlib inline
# %load_ext tensorboard
# Load TensorBoard notebook extension
#Import SummaryWriter for instntination 
from torch.utils.tensorboard import SummaryWriter
from sklearn.model_selection import train_test_split    # for sipliting dataset 

import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
import numpy as np
import os
import os.path
import cv2
from PIL import Image
import theano

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
from torchvision import transforms, models, datasets
import torch.utils.data as loader
import torch.optim as optim
from torch.optim import lr_scheduler
import torchvision.models as models

import pandas as pd
from typing import Any, Callable, List, Optional, Union, Tuple
from PIL import Image

from torchvision.datasets.vision import VisionDataset
from torchvision.datasets.utils import download_url, check_integrity

from torchvision.utils import make_grid
from torchvision.utils import save_image
from IPython.display import Image
import matplotlib.pyplot as plt
import numpy as np
import random
# %matplotlib inline

from sklearn.model_selection import train_test_split
import math
import shutil
import time
import copy 
from typing import List
import argparse
import glob
# from sklearn import datasets
import torchvision
import torchvision.datasets

log_dir = "/content/log/"
writer = SummaryWriter(log_dir)

"""## 1. Dataset 
Load the dataset you were given. Images should be stored in an X variable and your labels in a Y variable. Split your dataset into train, validation and test set and pre-process your data for training.

#### Loading the dataset
Show some images and labels of your dataset
"""

# ADD YOUR CODE HERE

### Download the dataset ###
dataset_url = "https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz"
download_url(dataset_url, '.')
### Extract from archive ###
with tarfile.open('./imagenette2-320.tgz','r:gz') as tar:
    tar.extractall(path='./data')

x = datasets.ImageFolder('./data/imagenette2-320/train')

def list_files(path):
    files = os.listdir(path)
    return np.asarray(files)

def split_files(oldpath, newpath, classes):
    for name in classes:
        full_dir = os.path.join(os.getcwd(), f"{oldpath}/{name}")

        files = list_files(x)
        total_file = np.size(files,0)
        # split data set into 3: train, validation and test

        train_size = math.ceil(total_file * 3/4) # 75% for training 

        validation_size = math.ceil(total_file * 1/8) # 12.5% for validation
        test_size = validation_size + math.ceil(total_file * 1/8) # 12.5x% for testing 

        # train = files[0:train_size]
        # validation = files[train_size:validation_size]
        test = files[validation_size:]

        # move_files(train, full_dir, f"train/{name}")
        # move_files(validation, full_dir, f"validation/{name}")
        move_files(test, full_dir, f"test/{name}")

        def move_files(files, old_dir, new_dir):
          new_dir = os.path.join(os.getcwd(), new_dir);
          if not os.path.exists(new_dir):
             os.makedirs(new_dir)

          for file in np.nditer(files):
            old_file_path = os.path.join(os.getcwd(), f"{old_dir}/{file}")
            new_file_path = os.path.join(os.getcwd(), f"{new_dir}/{file}")
            shutil.move(old_file_path, new_file_path)

transform = transforms.Compose([transforms.ToTensor(),transforms.Resize(256),transforms.CenterCrop(224),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
# train_dataset = datasets.ImageFolder("/content/5fruits/Training", transform=transform)
# test_dataset = datasets.ImageFolder("/content/5fruits/Test", transform=transform)
trainset = datasets.ImageFolder('./data/imagenette2-320/train', transform=transform)
class_map = {value : key for key, value in trainset.class_to_idx.items()}
val_dataset =  datasets.ImageFolder('./data/imagenette2-320/val', transform=transform)

# 10-11-2021
# classes = ('tench', 'English springer', 'cassette player', 'chain saw', 'church')
# data_dir2 = './'
# image_datasets = {x: torchvision.datasets.ImageFolder(os.path.join(data_dir2, x), transform[x]) for x in ['trainset', 'testset', 'val_dataset']}
# dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=64, shuffle=True, num_workers=2) for x in ['trainset', 'testset', 'val_dataset']}
# dataset_sizes = {x: len(image_datasets[x]) for x in ['trainset', 'testset', 'val_dataset']}
# class_names = image_datasets['trainset'].classes
# print("List of keys and associated class:")
# print((classes))

"""#### Splitting the dataset"""

# #spliting dataset 
# testset, test_dataset = train_test_split(val_dataset, test_size=0.40,shuffle=True, random_state=9)

# print(f"Train set count: {len(trainset)}")
# print(f"Validation set count: {len(val_dataset)}")
# print(f"Test set count: {len(test_dataset)}")
# # print(trainset.shape)

# ADD YOUR CODE HERE

"""#### Pre-processing the dataset"""

# ADD YOUR CODE HERE

### Data transforms (normalization & data augmentation) ###

# stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
# tran_tfms = transforms.Compose([transforms.RandomCrop(150, padding=4, padding_mode='reflect'), 
#                          transforms.RandomHorizontalFlip(), 
#                          transforms.ToTensor(), 
#                          transforms.Normalize(*stats,inplace=True)])
# valid_tfms = transforms.Compose([transforms.Resize([150,150]), transforms.ToTensor(), transforms.Normalize(*stats)])
#   # transform = transforms.Compose(
#   #     [transforms.ToTensor(),
#   #      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

### Making datasets ###
# trainset = ImageFolder('./data/imagenette2-320/train', tran_tfms)
# testset =  ImageFolder('./data/imagenette2-320/val', valid_tfms)
batch_size = 64
# ### PyTorch data loaders ###
# # trainloader = torch.utils.data.DataLoader(trainset, batch_size, shuffle=True, num_workers=3, pin_memory=True)
# trainloader = DataLoader(trainset, batch_size=batch_size,shuffle=True, num_workers=2)
# #10/11/2021---------------------------------------------------------------------------
# # testloader = torch.utils.data.DataLoader(testset, batch_size*2, num_workers=3, pin_memory=True)
# testloader = DataLoader(testset, batch_size=batch_size,shuffle=False, num_workers=2)
# # print(len(testloader))
# classes = ('tench', 'English springer', 'cassette player', 'chain saw', 'church')
# transform = transforms.Compose([transforms.ToTensor(),
#                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
# train_dataset = datasets.ImageFolder("/content/5fruits/Training", transform=transform)

# class_map = {value : key for key, value in train_dataset.class_to_idx.items()}
# test_dataset = datasets.ImageFolder("/content/5fruits/Test", transform=transform)
# print("List of keys and associated class:")
# print((class_map))
### PyTorch data loaders ###
# train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)
# valid_dl = DataLoader(valid_ds, batch_size*2, num_workers=3, pin_memory=True)
trainloader    = torch.utils.data.DataLoader(dataset=trainset,batch_size=batch_size, shuffle=True,num_workers=3)
val_dataloader = torch.utils.data.DataLoader(dataset=val_dataset*2, batch_size=batch_size, shuffle=True)
testloader     = torch.utils.data.DataLoader(dataset=testset,batch_size=batch_size, shuffle=True,num_workers=2)

### Data visiualisation ###
# def show_batch(dl):
#     for images, labels in dl:
#         fig, ax = plt.subplots(figsize=(12, 12))
#         ax.set_xticks([]); ax.set_yticks([])
#         ax.imshow(make_grid(images[:16], nrow=8).permute(1, 2, 0))  #reorder the channels 
#         break
# show_batch(trainloader)
# print(trainloader)
# Imagenette is a subset of 10 easily classified classes from Imagenet has the following 5 classes: (only 5 chossen)
classes = ('tench', 'English springer', 'cassette player', 'chain saw', 'church')
# print(trainset)
# -------------------------
# functions to show an image
# images and labels on our dataset
def imshow(img):
    img = img / 2 + 0.5     #because images were normalized when loaded, for visualization purposes we unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0))) #reorder the channels 
    plt.show()


# # get some random training images
# dataiter = iter(trainloader)
# images, labels = dataiter.next()

# # print labels
# # print(' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))
# # show images
# imshow(torchvision.utils.make_grid(images))

### Data visiualisation ###
def show_batch(trainloader):
    for images, labels in trainloader:
        fig, ax = plt.subplots(figsize=(12, 12))
        ax.set_xticks([]); ax.set_yticks([])
        ax.imshow(make_grid(images[:64], nrow=8).permute(1, 2, 0))
        break
dataiter = iter(trainloader)
images, labels = dataiter.next()
show_batch(trainloader)

"""## 2. Convolutional Neural Network Architecture
Load the CNN architecture you were given using pretrained weights. Define the optimizer and loss function. Train your network and save it. Remember to use Early stopping and show results with Tensorboard.

#### Load the architecture
"""

# ADD YOUR CODE HERE

# ADD YOUR CODE HERE
#Set up GPU
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Assuming that we are on a CUDA machine, this should print a CUDA device:
print(device)
# # Find the device available to use using torch library
# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# Move model to the device specified above

# ADD YOUR CODE HERE
"""
A from scratch implementation of the VGG architecture.
I made dynmic for all types of vgg
"""
# Convolutional neural network 
# VGG_types = {
#     # "VGG11": [64, "M", 128, "M", 256, 256, "M", 512, 512, "M", 512, 512, "M"],
#     # "VGG13": [64, 64, "M", 128, 128, "M", 256, 256, "M", 512, 512, "M", 512, 512, "M"],
#     # "VGG16": [64,64,"M",128,128,"M",256,256,256,"M",512,512,512,"M",512,512,512,"M"] #,
#     # "VGG19": [64,64,"M",128,128,"M",256,256,256,256,"M",512,512,512,512,"M",512,512,512,512,"M"]
#             }

# class VGG_net16(nn.Module): # inherent from the model 
#     def __init__(self, in_channels=3, num_classes=5):
#     # def __init__(self, in_channels=3, num_classes=1000):

#         super(VGG_net16, self).__init__()
#         self.in_channels = in_channels
#         self.conv_layers = self.create_conv_layers(VGG_types["VGG16"])  # call the function 

#         # fully connected part 
#          #First convolutional layer
#         #nn.Sequential can help us group multiple modules together.
#         ## Create new classifier for model using torch.nn as nn library
#         self.fcs = nn.Sequential(
#             nn.Linear(512 * 7 * 7, 4096), #= 25088 in_feachers  # (number of channels * number of pic , )  224/ 2**5(MaxPol) = 7
#             # nn.Linear(512* 7*7, 4096), #= 25088 in_feachers  # (number of channels * number of pic , )  224/ 2**5(MaxPol) = 7
#             nn.ReLU(),
#             nn.Dropout(p=0.5),
#             nn.Linear(4096, 4096),
#             nn.ReLU(),
#             nn.Dropout(p=0.5),
#             nn.Linear(4096, num_classes),
#         )

#     def forward(self, x):
#         x = self.conv_layers(x)
#         x = x.reshape(x.shape[0], -1)
#         x = self.fcs(x)
#         return x

#     def create_conv_layers(self, architecture):
#         layers = []
#         in_channels = self.in_channels

#         for x in architecture:
#             if type(x) == int:
#                 out_channels = x

#                 layers += [
#                     nn.Conv2d(
#                         in_channels=in_channels,
#                         out_channels=out_channels,
#                         kernel_size=(3, 3),
#                         stride=(1, 1),
#                         padding=(1, 1),
#                     ),
#                     nn.BatchNorm2d(x),
# # nn.ReLU is an activation function for hidden layers. Activation functions helps the model 
# # learn complex relationships between the input and the output. We use ReLU on all layers except for the output         
#                     nn.ReLU(),
#                 ]
#                 in_channels = x   # to update channal 
#             elif x == "M":
# # Applies a 2D max pooling over an input signal composed of several input planes.
#                 layers += [nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))]
#         return nn.Sequential(*layers)


# if __name__ == "__main__":
# Find the device available to  using torch library
# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# Move model to the device specified above
device = "cuda" if torch.cuda.is_available() else "cpu"
model = torchvision.models.vgg16(pretrained=True)
for param in model.parameters():

   param.requires_grad = False
# model = models.vgg16(pretrained=True)
# model = VGG_net16(in_channels=3, num_classes=5)
number_features = model.classifier[6].in_features
features = list(model.classifier.children())[:-1] # Remove last layer
features.extend([torch.nn.Linear(number_features, len(classes))])
model.classifier = torch.nn.Sequential(*features)
# model = VGG_net16(in_channels=3, num_classes=5).to(device)
model = model.to(device)

print(model)
    #  N = 3 #(Mini batch size)
# x = torch.randn(3, 3, 224, 224).to(device)   # generate some random data like having image 
# print(model(x).shape)  #(3 input, 1000 output)

"""#### Define your optimizer and loss function"""

# ADD YOUR CODE HERE

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
# optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-5)

"""#### Train your network"""

# ADD YOUR CODE HERE

import time
import copy
def train_model(model, criterion, optimizer, scheduler, num_epochs):
    since = time.time()
    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0
    best_loss = 0.0  
    for epoch in range(num_epochs):            

        print('Epoch {}/{} LR {:.6f}'.format(epoch, num_epochs - 1, scheduler.get_last_lr()[0]))

        print('-' * 10)
        # Each epoch has a training and validation phase

        for phase in ['train', 'validation']:
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode
            #print(model.train())
            running_loss = 0.0
            running_corrects = 0
            # Iterate over data.
            for inputs, labels in trainloader[phase]:
                inputs = inputs.to(device)

                labels = labels.to(device)

                #print(inputs)

                #print(labels)

                # zero the parameter gradients

                optimizer.zero_grad()
                # forward

                # track history if only in train

                with torch.set_grad_enabled(phase == 'train'):

                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)

                    loss = criterion(outputs, labels)
                    # backward + optimize only if in training phase

                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                # statistics

                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)
            if phase == 'train':
                scheduler.step()

            epoch_loss = running_loss / dataset_sizes[phase]

            epoch_acc = running_corrects.double() / dataset_sizes[phase]            # for plot

            writer.add_scalar('Training Loss', epoch_loss, epoch * dataset_sizes[phase] + epoch)

            writer.add_scalar('Training Accuracy', epoch_acc,epoch * dataset_sizes[phase] + epoch)           

            writer.add_scalar('Validation Loss', epoch_loss, epoch * dataset_sizes[phase])

            writer.add_scalar('Validation Accuracy', epoch_acc, epoch * dataset_sizes[phase])

            print('{} Loss: {:.4f} Acc: {:.4f}'.format(

                phase, epoch_loss, epoch_acc))
            # deep copy the model

            if phase == 'validation' and epoch_acc > best_acc:

                best_acc = epoch_acc
                break
                best_model_wts = copy.deepcopy(model.state_dict())
                writer.add_scalar('accuracy', best_acc)        
        print()
    time_elapsed = time.time() - since

    print('Training complete in {:.0f}m {:.0f}s'.format(

        time_elapsed // 60, time_elapsed % 60))

    print('Best val Acc: {:4f}'.format(best_acc))    

    # load best model weights

    #model.load_state_dict(best_model_wts)

    return model

# ADD YOUR CODE HERE
def evaluate():
  running_loss = 0.0 #    counter = 0
   # Tell torch not to calculate gradients
  with torch.no_grad():
    for i, data in enumerate(testloader, 0):
      # get the inputs; data is a list of [inputs, labels]
      inputs, labels = data
      # Move to device
      inputs = inputs.to(device = device)
      labels = labels.to(device = device)
      # Forward pass
      outputs = model(inputs)
      # Calculate Loss
      loss = criterion(outputs, labels)
      # Add loss to the validation set's running loss
      running_loss += loss.item()
    # Since our model  find the real percentages by  the  following 
  val_loss = running_loss / len(testloader)
  print('val loss: %.3f' % (val_loss))
     # Get the top class of the output
  return val_loss


def eval_acc(train=False):
  correct = 0
  total = 0
  # since we're not training, we don't need to calculate the gradients for our outputs
  with torch.no_grad():
      loader = trainloader if train else testloader 
      for data in loader:
          images, labels = data
          images = images.to(device = device)
          labels = labels.to(device = device)
          # calculate outputs by running images through the network
          outputs = model(images)
          # the class with the highest energy is what we choose as prediction
          _, predicted = torch.max(outputs.data, 1)
          total += labels.size(0)
          correct += (predicted == labels).sum().item()

   # Print out the information
  print('Accuracy of the network on the 10000 %s images: %d %%' % ('train' if train else 'test', 100 * correct / total))



"""#### Show results (accuracy and loss) on training and validation sets"""

# ADD YOUR CODE HERE

# torch.cuda.empty_cache()
NUM_EPOCHS = 2
for epoch in range(NUM_EPOCHS):  # loop over the dataset multiple times
    print(f'Epoch {epoch+1}:')
    running_loss = 0.0
    # Move to device
    for i, data in enumerate(trainloader, 0):
        print(data[0].shape)
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data
        inputs = inputs.to(device)
        labels = labels.to(device)
        # inputs, labels = data[0].to(device), data[1].to(device) #set for GPU if available
        # Clear optimizers
        # zero the parameter gradients
        optimizer.zero_grad()
         # Forward pass
        # forward + backward + optimize
       #############################     size mismatch, m1: [a x b], m2: [c x d] 
       #############################     m1 is [a x b] which is [batch size x in features]
       #############################     m2 is [c x d] which is [in features x out features]
        outputs = model(inputs.view(batch_size, -1))   
        print("Output shape:", outputs.shape)
        print("Target shape:", labels.max(), labels.min())
        # outputs = outputs[1:].reshape(-1, outputs.shape[2])
        # labels = labels[1:].reshape(-1)
        # print("Output shape 2:", outputs.shape)
        # print("Target shape 2:", labels.max(), labels.min())
        # outputs = 5
        # Loss
        loss = criterion(outputs, labels)
        #I assume you are using nn.CrossEntropyLoss or nn.NLLLoss as the criterion.
        # If so, check the output shape as well as the min. and max. values on targets.
        # As described before: for a multi-class classification the output should have the shape [batch_size, nb_classes], 
        # while the target is expected to have the shape [batch_size] and contain class indices in the range [0, nb_classes-1].
        # Calculate gradients (backpropogation)
        loss.backward()
        # Adjust parameters based on gradients
        optimizer.step()
        # Add the loss to the training set's rnning loss
        # print statistics
        running_loss += loss.item()
        # Print the progress of our training
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print(f'Iteration {i+1}, loss = {(running_loss / 2000):.3f}')
            running_loss = 0.0
    # Evaluating the model
    evaluate()
    # the above was That was great! Youâ€™ve just built an AI image classifier.
    eval_acc()

print('Finished Training')

PATH = './vgg16_net.pth'
torch.save(model.state_dict(), PATH)

"""## 3. Conclusion (Evaluation)
Load your trained CNN and evaluate it on the test set. Show some predictions on the test set (3 is enough) by ploting the image and printing the prediction and ground truth.

How good are your results? Do you think the network is overfitted or underfitted? If yes, what do you think lead to that? If not, justify.

#### Evaluate your model
"""

# ADD YOUR CODE HERE

correct = 0
total = 0
# since we're not training, we don't need to calculate the gradients for our outputs
with torch.no_grad():
    for data in testloader:
        #images, labels = data
        #inputs, labels = data[0].to(device), data[1].to(device) #set for GPU if available
        images, labels = data
        images = images.to(device)
        labels = labels.to(device)
        # calculate outputs by running images through the network
        outputs = model(images)
        # the class with the highest energy is what we choose as prediction
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on the 10000 test images: %d %%' % (
    100 * correct / total))

# prepare to count predictions for each class
correct_pred = {classname: 0 for classname in classes}
total_pred = {classname: 0 for classname in classes}

# again no gradients needed
with torch.no_grad():
    for data in testloader:
        images, labels = data
        # inputs, labels = data[0].to(device), data[1].to(device) #set for GPU if available
        outputs = model(images)
        _, predictions = torch.max(outputs, 1)
        # collect the correct predictions for each class
        for label, prediction in zip(labels, predictions):
            if label == prediction:
                correct_pred[classes[label]] += 1
            total_pred[classes[label]] += 1


# print accuracy for each class
for classname, correct_count in correct_pred.items():
    accuracy = 100 * float(correct_count) / total_pred[classname]
    print("Accuracy for class {:5s} is: {:.1f} %".format(classname,
                                                   accuracy))

"""#### Show some predictions"""

# ADD YOUR CODE HERE

w = model.cpu()
# w = w.reshape(10, 3, 32, 32).transpose(0, 2, 3, 1)
w_min, w_max = np.min(w), np.max(w)
classes = ['tench', 'English springer', 'cassette player', 'chain saw', 'church']
for i in range(3):
  plt.subplot(2, 5, i + 1)
  # Rescale the weights to be between 0 and 255
  #wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)
  wimg = 255.0 * (w[i].squeeze() - w_min) / (w_max - w_min)
  plt.imshow(wimg.astype('uint8'))
  plt.axis('off')
  plt.title(classes[i])

class EarlyStopping():
    """
    Early stopping to stop the training when the loss does not improve after
    certain epochs.
    """
    def __init__(self, patience=5, min_delta=0):  # patience need to wait for some epoch
        """
        :param patience: how many epochs to wait before stopping when loss is
               not improving
        :param min_delta: minimum difference between new loss and old loss for
               new loss to be considered as an improvement
        """
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_loss = None
        self.early_stop = False
        self.best_model = './cifar_best_net.pth'

    def __call__(self, val_loss):
        if self.best_loss == None:
            self.best_loss = val_loss
        elif self.best_loss - val_loss > self.min_delta:
            self.best_loss = val_loss
            torch.save(model.state_dict(), self.best_model)
        elif self.best_loss - val_loss < self.min_delta:
            self.counter += 1
            print(f"INFO: Early stopping counter {self.counter} of {self.patience}")
            if self.counter >= self.patience:
                print('INFO: Early stopping')
                self.early_stop = True

early_stopping = EarlyStopping()
model = VGG_net16().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

NUM_EPOCHS = 2 #100
for epoch in range(NUM_EPOCHS):  # loop over the dataset multiple times
    print(f'Epoch {epoch+1}:')
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        #inputs, labels = data
        images, labels = data[0].to(device), data[1].to(device) #set for GPU if available

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print(f'Iteration {i+1}, loss = {(running_loss / 2000):.3f}')
            running_loss = 0.0

    val_loss = evaluate()
    eval_acc()
    early_stopping(val_loss)
    if early_stopping.early_stop:
        break

print('Finished Training')

model = VGG_net16().to(device)
model.load_state_dict(torch.load(early_stopping.best_model))# load to the network best  model

"""#### Answer the questions"""

# ADD YOUR ANSWERS HERE
